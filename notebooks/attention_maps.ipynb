{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_240326/860917103.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
    "import pandas as pd\n",
    "from bertviz import head_view\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dev = \"../data/labeled-train.model-aware.v2.json\"\n",
    "df = pd.read_json(path_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 564/564 [00:00<00:00, 312kB/s]\n",
      "sentencepiece.bpe.model: 100%|██████████| 4.85M/4.85M [00:00<00:00, 12.9MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.3M/17.3M [00:01<00:00, 9.36MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 3.55k/3.55k [00:00<00:00, 20.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'Separation and reintegration continue to shift the differences between the two pools with each generation.',\n",
       " 'ref': 'either',\n",
       " 'src': 'अलगाव आ पुनर्संयोजन प्रत्येक पीढ़ीक संग द्विटा पूल सभक बीच फेरबदल भिन्नता कें आगू-पाछू करैत रहैत अछि।',\n",
       " 'tgt': 'Segregation and recombination shuffle variation back and forth between the two pools with each generation.',\n",
       " 'model': 'facebook/nllb-200-distilled-600M',\n",
       " 'task': 'MT',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Hallucination'],\n",
       " 'label': 'Hallucination',\n",
       " 'p(Hallucination)': 0.6000000000000001}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"task\"] == \"MT\"].iloc[2].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अलगाव आ पुनर्संयोजन प्रत्येक पीढ़ीक संग द्विटा पूल सभक बीच फेरबदल भिन्नता कें आगू-पाछू करैत रहैत अछि।'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = df[df[\"task\"] == \"\"].iloc[2][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from one generation to the next.</s><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from one generation to the next.</s>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools with each generation.</s><pad><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from generation to generation.</s><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from generation to generation.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools with each generation.</s><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a significant difference between the two pools from generation to generation.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from one generation to another.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continue to bring about change between the two pools with each generation.</s><pad><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from one generation to another.</s><pad>']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(**tokens, \n",
    "                         forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"],\n",
    "                         num_beams=10,\n",
    "                         do_sample=True,\n",
    "                         num_return_sequences=1)\n",
    "text = tokenizer.batch_decode(outputs)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>labels</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sloping top .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The sides of the casket were covered with heav...</td>\n",
       "      <td>A decorative feature that sits on top of somet...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To react too much .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please try not to overreact if she drives badl...</td>\n",
       "      <td>To react too much or too intensely .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The process of spoiling ; the state of being s...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To prevent spoilage , store in a cool , dry pl...</td>\n",
       "      <td>The process of spoiling .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To arrange in a particular way .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The way the opposition has framed the argument...</td>\n",
       "      <td>To construct in words so as to establish a con...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A feeling of concern ; a feeling of anxiety .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To mix with thy concernments i desist . What i...</td>\n",
       "      <td>That in which one is concerned or interested ;...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Of or pertaining to communism .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Communistic birds . What is the meaning of com...</td>\n",
       "      <td>Living or having their nests in common .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The act of treating a disease or condition .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Lahmann 's unprecedented success proved beyond...</td>\n",
       "      <td>Attempted remediation of a health problem foll...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Able to be collected .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>He 's owed it to us for six months , but it do...</td>\n",
       "      <td>That is likely to be paid .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Not Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>A native or inhabitant of the us state of uson...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>As a usonian of celtic-franco/gallego mexican-...</td>\n",
       "      <td>An inhabitant or citizen of the United States ...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A loan .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please do me a solid : lend me your car for on...</td>\n",
       "      <td>A favor .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hyp  ref  \\\n",
       "0                                      A sloping top .  tgt   \n",
       "1                                  To react too much .  tgt   \n",
       "2    The process of spoiling ; the state of being s...  tgt   \n",
       "3                     To arrange in a particular way .  tgt   \n",
       "4        A feeling of concern ; a feeling of anxiety .  tgt   \n",
       "..                                                 ...  ...   \n",
       "183                    Of or pertaining to communism .  tgt   \n",
       "184       The act of treating a disease or condition .  tgt   \n",
       "185                             Able to be collected .  tgt   \n",
       "186  A native or inhabitant of the us state of uson...  tgt   \n",
       "187                                           A loan .  tgt   \n",
       "\n",
       "                                                   src  \\\n",
       "0    The sides of the casket were covered with heav...   \n",
       "1    Please try not to overreact if she drives badl...   \n",
       "2    To prevent spoilage , store in a cool , dry pl...   \n",
       "3    The way the opposition has framed the argument...   \n",
       "4    To mix with thy concernments i desist . What i...   \n",
       "..                                                 ...   \n",
       "183  Communistic birds . What is the meaning of com...   \n",
       "184  Lahmann 's unprecedented success proved beyond...   \n",
       "185  He 's owed it to us for six months , but it do...   \n",
       "186  As a usonian of celtic-franco/gallego mexican-...   \n",
       "187  Please do me a solid : lend me your car for on...   \n",
       "\n",
       "                                                   tgt  \\\n",
       "0    A decorative feature that sits on top of somet...   \n",
       "1                 To react too much or too intensely .   \n",
       "2                            The process of spoiling .   \n",
       "3    To construct in words so as to establish a con...   \n",
       "4    That in which one is concerned or interested ;...   \n",
       "..                                                 ...   \n",
       "183           Living or having their nests in common .   \n",
       "184  Attempted remediation of a health problem foll...   \n",
       "185                        That is likely to be paid .   \n",
       "186  An inhabitant or citizen of the United States ...   \n",
       "187                                          A favor .   \n",
       "\n",
       "                              model task  \\\n",
       "0    ltg/flan-t5-definition-en-base   DM   \n",
       "1    ltg/flan-t5-definition-en-base   DM   \n",
       "2    ltg/flan-t5-definition-en-base   DM   \n",
       "3    ltg/flan-t5-definition-en-base   DM   \n",
       "4    ltg/flan-t5-definition-en-base   DM   \n",
       "..                              ...  ...   \n",
       "183  ltg/flan-t5-definition-en-base   DM   \n",
       "184  ltg/flan-t5-definition-en-base   DM   \n",
       "185  ltg/flan-t5-definition-en-base   DM   \n",
       "186  ltg/flan-t5-definition-en-base   DM   \n",
       "187  ltg/flan-t5-definition-en-base   DM   \n",
       "\n",
       "                                                labels              label  \\\n",
       "0    [Not Hallucination, Hallucination, Not Halluci...      Hallucination   \n",
       "1    [Not Hallucination, Not Hallucination, Not Hal...  Not Hallucination   \n",
       "2    [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "3    [Hallucination, Not Hallucination, Not Halluci...      Hallucination   \n",
       "4    [Not Hallucination, Hallucination, Hallucinati...      Hallucination   \n",
       "..                                                 ...                ...   \n",
       "183  [Hallucination, Hallucination, Hallucination, ...      Hallucination   \n",
       "184  [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "185  [Hallucination, Hallucination, Not Hallucinati...      Hallucination   \n",
       "186  [Hallucination, Hallucination, Hallucination, ...      Hallucination   \n",
       "187  [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "\n",
       "     p(Hallucination)  \n",
       "0                 0.6  \n",
       "1                 0.0  \n",
       "2                 0.6  \n",
       "3                 0.6  \n",
       "4                 0.6  \n",
       "..                ...  \n",
       "183               1.0  \n",
       "184               0.6  \n",
       "185               0.8  \n",
       "186               1.0  \n",
       "187               0.8  \n",
       "\n",
       "[188 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"task\"] == \"DM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ltg/flan-t5-definition-en-base\",output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ltg/flan-t5-definition-en-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>labels</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sloping top .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The sides of the casket were covered with heav...</td>\n",
       "      <td>A decorative feature that sits on top of somet...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The process of spoiling ; the state of being s...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To prevent spoilage , store in a cool , dry pl...</td>\n",
       "      <td>The process of spoiling .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To arrange in a particular way .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The way the opposition has framed the argument...</td>\n",
       "      <td>To construct in words so as to establish a con...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A feeling of concern ; a feeling of anxiety .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To mix with thy concernments i desist . What i...</td>\n",
       "      <td>That in which one is concerned or interested ;...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To suffocate .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Having divested the child he kissed her gently...</td>\n",
       "      <td>To undress .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Of or pertaining to communism .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Communistic birds . What is the meaning of com...</td>\n",
       "      <td>Living or having their nests in common .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The act of treating a disease or condition .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Lahmann 's unprecedented success proved beyond...</td>\n",
       "      <td>Attempted remediation of a health problem foll...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Able to be collected .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>He 's owed it to us for six months , but it do...</td>\n",
       "      <td>That is likely to be paid .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Not Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>A native or inhabitant of the us state of uson...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>As a usonian of celtic-franco/gallego mexican-...</td>\n",
       "      <td>An inhabitant or citizen of the United States ...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A loan .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please do me a solid : lend me your car for on...</td>\n",
       "      <td>A favor .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hyp  ref  \\\n",
       "0                                      A sloping top .  tgt   \n",
       "2    The process of spoiling ; the state of being s...  tgt   \n",
       "3                     To arrange in a particular way .  tgt   \n",
       "4        A feeling of concern ; a feeling of anxiety .  tgt   \n",
       "6                                       To suffocate .  tgt   \n",
       "..                                                 ...  ...   \n",
       "183                    Of or pertaining to communism .  tgt   \n",
       "184       The act of treating a disease or condition .  tgt   \n",
       "185                             Able to be collected .  tgt   \n",
       "186  A native or inhabitant of the us state of uson...  tgt   \n",
       "187                                           A loan .  tgt   \n",
       "\n",
       "                                                   src  \\\n",
       "0    The sides of the casket were covered with heav...   \n",
       "2    To prevent spoilage , store in a cool , dry pl...   \n",
       "3    The way the opposition has framed the argument...   \n",
       "4    To mix with thy concernments i desist . What i...   \n",
       "6    Having divested the child he kissed her gently...   \n",
       "..                                                 ...   \n",
       "183  Communistic birds . What is the meaning of com...   \n",
       "184  Lahmann 's unprecedented success proved beyond...   \n",
       "185  He 's owed it to us for six months , but it do...   \n",
       "186  As a usonian of celtic-franco/gallego mexican-...   \n",
       "187  Please do me a solid : lend me your car for on...   \n",
       "\n",
       "                                                   tgt  \\\n",
       "0    A decorative feature that sits on top of somet...   \n",
       "2                            The process of spoiling .   \n",
       "3    To construct in words so as to establish a con...   \n",
       "4    That in which one is concerned or interested ;...   \n",
       "6                                         To undress .   \n",
       "..                                                 ...   \n",
       "183           Living or having their nests in common .   \n",
       "184  Attempted remediation of a health problem foll...   \n",
       "185                        That is likely to be paid .   \n",
       "186  An inhabitant or citizen of the United States ...   \n",
       "187                                          A favor .   \n",
       "\n",
       "                              model task  \\\n",
       "0    ltg/flan-t5-definition-en-base   DM   \n",
       "2    ltg/flan-t5-definition-en-base   DM   \n",
       "3    ltg/flan-t5-definition-en-base   DM   \n",
       "4    ltg/flan-t5-definition-en-base   DM   \n",
       "6    ltg/flan-t5-definition-en-base   DM   \n",
       "..                              ...  ...   \n",
       "183  ltg/flan-t5-definition-en-base   DM   \n",
       "184  ltg/flan-t5-definition-en-base   DM   \n",
       "185  ltg/flan-t5-definition-en-base   DM   \n",
       "186  ltg/flan-t5-definition-en-base   DM   \n",
       "187  ltg/flan-t5-definition-en-base   DM   \n",
       "\n",
       "                                                labels          label  \\\n",
       "0    [Not Hallucination, Hallucination, Not Halluci...  Hallucination   \n",
       "2    [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "3    [Hallucination, Not Hallucination, Not Halluci...  Hallucination   \n",
       "4    [Not Hallucination, Hallucination, Hallucinati...  Hallucination   \n",
       "6    [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "..                                                 ...            ...   \n",
       "183  [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "184  [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "185  [Hallucination, Hallucination, Not Hallucinati...  Hallucination   \n",
       "186  [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "187  [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "\n",
       "     p(Hallucination)  \n",
       "0                 0.6  \n",
       "2                 0.6  \n",
       "3                 0.6  \n",
       "4                 0.6  \n",
       "6                 1.0  \n",
       "..                ...  \n",
       "183               1.0  \n",
       "184               0.6  \n",
       "185               0.8  \n",
       "186               1.0  \n",
       "187               0.8  \n",
       "\n",
       "[89 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_hal = df[(df[\"task\"] == \"DM\") & (df[\"label\"] == \"Hallucination\")]\n",
    "dm_hal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing positive example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'To suffocate .',\n",
       " 'ref': 'tgt',\n",
       " 'src': 'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?',\n",
       " 'tgt': 'To undress .',\n",
       " 'model': 'ltg/flan-t5-definition-en-base',\n",
       " 'task': 'DM',\n",
       " 'labels': ['Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination'],\n",
       " 'label': 'Hallucination',\n",
       " 'p(Hallucination)': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
    "decoder_tokens = tokenizer.convert_ids_to_tokens(outputs.sequences[0])\n",
    "\n",
    "result = model(input_ids=tokens[\"input_ids\"],decoder_input_ids=outputs.sequences, use_cache=False,                \n",
    "        output_attentions=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(\n",
    "    encoder_attention=result.encoder_attentions,\n",
    "    decoder_attention=result.decoder_attentions,\n",
    "    cross_attention=result.cross_attentions,\n",
    "    encoder_tokens= encoder_tokens,\n",
    "    decoder_tokens = decoder_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing negative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'To react too much .',\n",
       " 'ref': 'tgt',\n",
       " 'src': 'Please try not to overreact if she drives badly when she is first learning . What is the meaning of overreact ?',\n",
       " 'tgt': 'To react too much or too intensely .',\n",
       " 'model': 'ltg/flan-t5-definition-en-base',\n",
       " 'task': 'DM',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'label': 'Not Hallucination',\n",
       " 'p(Hallucination)': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please try not to overreact if she drives badly when she is first learning . What is the meaning of overreact ?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")].iloc[0][\"src\"]\n",
    "src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
    "decoder_tokens = tokenizer.convert_ids_to_tokens(outputs.sequences[0])\n",
    "\n",
    "result = model(input_ids=tokens[\"input_ids\"],decoder_input_ids=outputs.sequences, use_cache=False,                \n",
    "        output_attentions=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(\n",
    "    encoder_attention=result.encoder_attentions,\n",
    "    decoder_attention=result.decoder_attentions,\n",
    "    cross_attention=result.cross_attentions,\n",
    "    encoder_tokens= encoder_tokens,\n",
    "    decoder_tokens = decoder_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq-Logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '▁To', '▁', 's', 'uff', 'o', 'cate', '▁', '.', '</s>']\n",
      "<pad> To suffocate.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(outputs.sequences[0]))\n",
    "print(tokenizer.decode(outputs.sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_score(outputs):\n",
    "    max_logprobs = [score.max() for score in outputs.scores]\n",
    "    conf_score = sum(max_logprobs) / len(max_logprobs)\n",
    "    return conf_score\n",
    "\n",
    "def generate(source):\n",
    "    tokens = tokenizer(source,return_tensors=\"pt\")\n",
    "    outputs = model.generate(**tokens,\n",
    "                            return_dict_in_generate=True,\n",
    "                            output_scores=True,)\n",
    "    return get_conf_score(outputs)\n",
    "\n",
    "def get_token_lengths(sequences):\n",
    "    tok_lens = []\n",
    "    for seq in sequences:\n",
    "        toks = tokenizer.convert_ids_to_tokens(seq,skip_special_tokens=True)\n",
    "        tok_lens.append(len(toks))\n",
    "    return torch.tensor(tok_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = dm_hal[dm_hal[\"p(Hallucination)\"] == 1][\"src\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(srcs,return_tensors=\"pt\",padding=True,truncation=True)\n",
    "outputs = model.generate(**tokens,\n",
    "                        return_dict_in_generate=True,\n",
    "                        output_scores=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.4071,  5.3401, -0.2419,  0.8012,  5.9969,  4.8076,  4.0492,  3.5485,\n",
       "         6.0472,  4.6019,  6.1943,  4.1186,  7.5194,  5.5130,  3.0846,  4.9129,\n",
       "         4.3745,  4.8689,  3.2190,  7.8033, 10.2741,  7.3097,  4.6601,  7.4027,\n",
       "         6.3553,  3.5634,  5.4295, 10.4581,  5.3850,  8.9073,  6.4095,  4.3153,\n",
       "         6.9461,  5.1326,  4.2383])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lens = get_token_lengths(outputs.sequences)\n",
    "#TODO: don't include conf scores from pad tokens\n",
    "conf_scores = torch.stack([torch.max(score,dim=1).values for score in outputs.scores]).sum(0)  / tok_lens\n",
    "conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2419)\n",
      "tensor(10.4581)\n"
     ]
    }
   ],
   "source": [
    "print(conf_scores.min())\n",
    "print(conf_scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")][\"src\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(srcs,return_tensors=\"pt\",padding=True,truncation=True)\n",
    "outputs = model.generate(**tokens,\n",
    "                        return_dict_in_generate=True,\n",
    "                        output_scores=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.4396,  3.7341,  5.8660,  4.8929,  2.1771, 13.0546,  8.6266,  4.7140,\n",
       "         3.3716,  5.6011, 17.0202,  5.0676,  4.2212, 11.1073,  4.7932,  6.5653,\n",
       "        24.7344,  5.5094,  7.6758,  6.1724,  3.6417,  5.7009,  8.1423, 13.5789,\n",
       "         6.1132,  7.8263, 32.1291,  5.4459,  4.7539,  4.6217,  6.5457])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lens = get_token_lengths(outputs.sequences)\n",
    "conf_scores = torch.stack([torch.max(score,dim=1).values for score in outputs.scores]).sum(0) / tok_lens\n",
    "conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1771)\n",
      "tensor(32.1291)\n"
     ]
    }
   ],
   "source": [
    "print(conf_scores.min())\n",
    "print(conf_scores.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden States Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dev = \"../data/labeled-train.model-aware.v2.json\"\n",
    "df = pd.read_json(path_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"DM\"\n",
    "FILTER = False\n",
    "\n",
    "task_df = df[(df[\"task\"] == TASK)] \n",
    "model_name = task_df[\"model\"].unique().item()\n",
    "if FILTER:\n",
    "    task_df = task_df[(task_df[\"p(Hallucination)\"] == 0) | (task_df[\"p(Hallucination)\"]==1)]\n",
    "task_df = task_df[[\"src\",\"label\"]]\n",
    "task_df[\"label\"] = task_df[\"label\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"mps\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # turned out to be the best size, larger ones result in worse detections\n",
    "batched_df = [task_df[i:i+batch_size] for i in range(0,len(task_df),batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(outputs):\n",
    "    eos_indices = []\n",
    "    for seq in outputs.sequences:\n",
    "        nonzero = (seq == tokenizer.eos_token_id).nonzero()\n",
    "        if nonzero.nelement() != 0:\n",
    "            idx = nonzero.item()\n",
    "        else:\n",
    "            idx = seq.size(0)-1 #last token\n",
    "        eos_indices.append(idx-1) #skip first pad token    \n",
    "    eos_indices = torch.tensor(eos_indices,device=device)\n",
    "\n",
    "    decoder_hidden_states = []\n",
    "    for t in outputs.decoder_hidden_states:\n",
    "        decoder_hidden_states.append(torch.stack(t))\n",
    "    decoder_hidden_states = torch.stack(decoder_hidden_states)\n",
    "    seq_len,layers,batch, _, hidden_dim = decoder_hidden_states.size()\n",
    "    decoder_hidden_states = decoder_hidden_states.reshape((layers,batch,seq_len,-1))\n",
    "\n",
    "    eos_indices = eos_indices.reshape((1,-1,1,1)).repeat(layers,1,1,hidden_dim)\n",
    "    hiddens = decoder_hidden_states.gather(dim=2,index=eos_indices).squeeze(2)\n",
    "    return hiddens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/DM-train.pkl\", \"rb\") as f:\n",
    "    hiddens,labels = pickle.load(f)\n",
    "\n",
    "# start_batch = 0\n",
    "# dataset = []\n",
    "# for batch in tqdm.tqdm(batched_df[start_batch:],total=len(batched_df[start_batch:])):\n",
    "#     tokens = tokenizer(batch[\"src\"].to_list(),\n",
    "#                     return_tensors=\"pt\",\n",
    "#                     padding=True,\n",
    "#                     truncation=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.generate(**tokens,\n",
    "#                                 max_new_tokens=25,\n",
    "#                                 return_dict_in_generate=True,\n",
    "#                                 output_hidden_states=True)\n",
    "#     hiddens = get_hidden_states(outputs)\n",
    "#     dataset.append((hiddens.to(\"cpu\"),batch[\"label\"].cat.codes.values))\n",
    "# hiddens,labels = list(zip(*dataset))\n",
    "# hiddens = torch.cat(hiddens,dim=1)\n",
    "# labels = np.concatenate(labels)\n",
    "# with open(\"hidden.pkl\", \"wb\") as f:\n",
    "#     pickle.dump((hiddens,labels),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiddens[layer_num].size()\n",
    "labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = hiddens.size(-1)\n",
    "class StatesClassifier(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear(hidden_dim,256)\n",
    "        self.ln2 = nn.Linear(256,128)\n",
    "        self.ln3 = nn.Linear(128,64)\n",
    "        self.head = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x).relu()\n",
    "        x = self.ln2(x).relu()\n",
    "        x = self.ln3(x).relu()\n",
    "        return self.head(x).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = StatesClassifier().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index,loader):\n",
    "    running_loss = 0.\n",
    "    \n",
    "    for i, data in enumerate(loader):        \n",
    "        inputs, labels = data\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = classifier(inputs.to(device))\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()        \n",
    "\n",
    "    return running_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 1.809154839486095 valid 1.3699495792388916\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 2:\n",
      "LOSS train 1.6973109913210498 valid 1.3730589151382446\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 3:\n",
      "LOSS train 1.6937941563256242 valid 1.2456235885620117\n",
      "Valid ACC 0.6904296875\n",
      "EPOCH 4:\n",
      "LOSS train 1.6844726184792553 valid 1.2128487825393677\n",
      "Valid ACC 0.6875\n",
      "EPOCH 5:\n",
      "LOSS train 1.6228884999633681 valid 1.2178575992584229\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 6:\n",
      "LOSS train 1.6259956847057275 valid 1.221069097518921\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 7:\n",
      "LOSS train 1.6320871089367157 valid 1.2257506847381592\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 8:\n",
      "LOSS train 1.665392702669962 valid 1.2318390607833862\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 9:\n",
      "LOSS train 1.4847571821288859 valid 0.8308987617492676\n",
      "Valid ACC 0.69140625\n",
      "EPOCH 10:\n",
      "LOSS train 0.6512302348377011 valid 0.6673679947853088\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 11:\n",
      "LOSS train 0.6321208630259155 valid 0.684244692325592\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 12:\n",
      "LOSS train 0.6296492290835008 valid 0.6860612034797668\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 13:\n",
      "LOSS train 0.6291357740654168 valid 0.690027117729187\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 14:\n",
      "LOSS train 0.6230602258063377 valid 0.6915683150291443\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 15:\n",
      "LOSS train 0.6201920519906579 valid 0.6878002285957336\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 16:\n",
      "LOSS train 0.6202221477919436 valid 0.7059763073921204\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 17:\n",
      "LOSS train 0.6134936693289601 valid 0.7247423529624939\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 18:\n",
      "LOSS train 0.6110719239458124 valid 0.7317399382591248\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 19:\n",
      "LOSS train 0.6194245889254496 valid 0.7351299524307251\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 20:\n",
      "LOSS train 0.6087536900601489 valid 0.7357775568962097\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 1:\n",
      "LOSS train 0.7711451457324603 valid 0.82523113489151\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 2:\n",
      "LOSS train 0.6473372821689497 valid 0.8267092704772949\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 3:\n",
      "LOSS train 0.6258776879056971 valid 0.8277171850204468\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 4:\n",
      "LOSS train 0.607922670266307 valid 0.8374463319778442\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 5:\n",
      "LOSS train 0.5920752240410934 valid 0.6617836356163025\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 6:\n",
      "LOSS train 0.5857802281777064 valid 0.6842005848884583\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 7:\n",
      "LOSS train 0.5828624933112597 valid 0.6862316131591797\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 8:\n",
      "LOSS train 0.5736528400410997 valid 0.7203700542449951\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 9:\n",
      "LOSS train 0.5702515354393222 valid 0.7234757542610168\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 10:\n",
      "LOSS train 0.5645627808486317 valid 0.7363974452018738\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 11:\n",
      "LOSS train 0.5574678040988056 valid 0.7630468010902405\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 12:\n",
      "LOSS train 0.556713452892946 valid 0.8762431740760803\n",
      "Valid ACC 0.6689453125\n",
      "EPOCH 13:\n",
      "LOSS train 0.5463973413228144 valid 0.8666284084320068\n",
      "Valid ACC 0.6689453125\n",
      "EPOCH 14:\n",
      "LOSS train 0.5387518644755613 valid 0.8128743767738342\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 15:\n",
      "LOSS train 0.5278647153090078 valid 1.0176734924316406\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 16:\n",
      "LOSS train 0.521361102449133 valid 1.0097321271896362\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 17:\n",
      "LOSS train 0.5166453481354611 valid 1.0356887578964233\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 18:\n",
      "LOSS train 0.506045752277611 valid 1.0797325372695923\n",
      "Valid ACC 0.662109375\n",
      "EPOCH 19:\n",
      "LOSS train 0.5014565407384372 valid 1.0811654329299927\n",
      "Valid ACC 0.6669921875\n",
      "EPOCH 20:\n",
      "LOSS train 0.49439648892862575 valid 1.1950451135635376\n",
      "Valid ACC 0.666015625\n",
      "EPOCH 1:\n",
      "LOSS train 0.7150552720888287 valid 0.6404538154602051\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 2:\n",
      "LOSS train 0.6568370565032282 valid 0.6560916304588318\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 3:\n",
      "LOSS train 0.6477399038296219 valid 0.741821825504303\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 4:\n",
      "LOSS train 0.6376074235490028 valid 0.7560974955558777\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6311007671533747 valid 0.763170063495636\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 6:\n",
      "LOSS train 0.6242064181583148 valid 0.7778728008270264\n",
      "Valid ACC 0.6708984375\n",
      "EPOCH 7:\n",
      "LOSS train 0.6179656924296778 valid 0.7949562072753906\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 8:\n",
      "LOSS train 0.6098841531268249 valid 0.8100235462188721\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 9:\n",
      "LOSS train 0.6033249020787841 valid 0.8497471213340759\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 10:\n",
      "LOSS train 0.5989170596531942 valid 0.877117395401001\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 11:\n",
      "LOSS train 0.5899757701665798 valid 0.9190963506698608\n",
      "Valid ACC 0.6669921875\n",
      "EPOCH 12:\n",
      "LOSS train 0.5839078210769816 valid 0.9387542605400085\n",
      "Valid ACC 0.6650390625\n",
      "EPOCH 13:\n",
      "LOSS train 0.5822691345679845 valid 0.9719719290733337\n",
      "Valid ACC 0.6611328125\n",
      "EPOCH 14:\n",
      "LOSS train 0.5780442935143802 valid 0.9581827521324158\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 15:\n",
      "LOSS train 0.5734329677008568 valid 1.005137324333191\n",
      "Valid ACC 0.671875\n",
      "EPOCH 16:\n",
      "LOSS train 0.5670040223404025 valid 1.0214725732803345\n",
      "Valid ACC 0.6640625\n",
      "EPOCH 17:\n",
      "LOSS train 0.561608429601852 valid 1.0451481342315674\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 18:\n",
      "LOSS train 0.5571946626436626 valid 1.128926396369934\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 19:\n",
      "LOSS train 0.5513800083534092 valid 1.1492528915405273\n",
      "Valid ACC 0.6640625\n",
      "EPOCH 20:\n",
      "LOSS train 0.5476012779465804 valid 1.1942840814590454\n",
      "Valid ACC 0.6630859375\n",
      "EPOCH 1:\n",
      "LOSS train 0.7709047166590995 valid 0.8213797807693481\n",
      "Valid ACC 0.6904296875\n",
      "EPOCH 2:\n",
      "LOSS train 0.6801775510006762 valid 0.8414537906646729\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 3:\n",
      "LOSS train 0.6737499639708945 valid 0.835166871547699\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 4:\n",
      "LOSS train 0.6712929022016255 valid 0.8330309987068176\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6626368327766445 valid 0.8465840220451355\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 6:\n",
      "LOSS train 0.6539635576889025 valid 0.8537942171096802\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 7:\n",
      "LOSS train 0.6482077096159576 valid 0.8572307825088501\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 8:\n",
      "LOSS train 0.6435490792736094 valid 0.8615428805351257\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 9:\n",
      "LOSS train 0.6405012928847725 valid 0.8753994107246399\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 10:\n",
      "LOSS train 0.6340727853648206 valid 0.8815920948982239\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 11:\n",
      "LOSS train 0.6299552671241422 valid 0.896030843257904\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 12:\n",
      "LOSS train 0.623021606540849 valid 0.9038302302360535\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 13:\n",
      "LOSS train 0.6194759284984981 valid 0.917228639125824\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 14:\n",
      "LOSS train 0.6111737133551997 valid 0.9385172724723816\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 15:\n",
      "LOSS train 0.6093793949970963 valid 0.9574297070503235\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 16:\n",
      "LOSS train 0.6037442707423623 valid 0.9743881821632385\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 17:\n",
      "LOSS train 0.6018444205640902 valid 0.9851020574569702\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 18:\n",
      "LOSS train 0.596740593829899 valid 1.0070029497146606\n",
      "Valid ACC 0.6669921875\n",
      "EPOCH 19:\n",
      "LOSS train 0.593796452309223 valid 1.000270962715149\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 20:\n",
      "LOSS train 0.5948597891322265 valid 1.0330418348312378\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 1:\n",
      "LOSS train 0.9145417458622168 valid 1.0115290880203247\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 2:\n",
      "LOSS train 0.811608410367729 valid 1.0107319355010986\n",
      "Valid ACC 0.6875\n",
      "EPOCH 3:\n",
      "LOSS train 0.7991222588094413 valid 1.010632872581482\n",
      "Valid ACC 0.6875\n",
      "EPOCH 4:\n",
      "LOSS train 0.7948434620250201 valid 1.018953561782837\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 5:\n",
      "LOSS train 0.7914059479185875 valid 1.03020441532135\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 6:\n",
      "LOSS train 0.7863890435678739 valid 1.0236632823944092\n",
      "Valid ACC 0.6904296875\n",
      "EPOCH 7:\n",
      "LOSS train 0.7832026755344783 valid 1.0335317850112915\n",
      "Valid ACC 0.69140625\n",
      "EPOCH 8:\n",
      "LOSS train 0.7778433875200597 valid 1.0640978813171387\n",
      "Valid ACC 0.6923828125\n",
      "EPOCH 9:\n",
      "LOSS train 0.7721086126481388 valid 1.0564830303192139\n",
      "Valid ACC 0.6904296875\n",
      "EPOCH 10:\n",
      "LOSS train 0.7672758126723851 valid 1.0490247011184692\n",
      "Valid ACC 0.6923828125\n",
      "EPOCH 11:\n",
      "LOSS train 0.7630663450728071 valid 1.058154821395874\n",
      "Valid ACC 0.693359375\n",
      "EPOCH 12:\n",
      "LOSS train 0.759553943437042 valid 1.0706201791763306\n",
      "Valid ACC 0.6943359375\n",
      "EPOCH 13:\n",
      "LOSS train 0.7577015739594791 valid 1.0639500617980957\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 14:\n",
      "LOSS train 0.7533567428377503 valid 1.0655931234359741\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 15:\n",
      "LOSS train 0.7506129780771039 valid 1.1290949583053589\n",
      "Valid ACC 0.6875\n",
      "EPOCH 16:\n",
      "LOSS train 0.750615287757089 valid 1.102723240852356\n",
      "Valid ACC 0.6904296875\n",
      "EPOCH 17:\n",
      "LOSS train 0.7485358476216066 valid 1.197540044784546\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 18:\n",
      "LOSS train 0.743073581803775 valid 1.2053664922714233\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 19:\n",
      "LOSS train 0.7406070447982626 valid 1.2144895792007446\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 20:\n",
      "LOSS train 0.7397751312517951 valid 1.2285243272781372\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 1:\n",
      "LOSS train 0.7542417924454872 valid 0.6293352246284485\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 2:\n",
      "LOSS train 0.649273749995739 valid 0.632125735282898\n",
      "Valid ACC 0.6875\n",
      "EPOCH 3:\n",
      "LOSS train 0.6390255276404374 valid 0.6495035290718079\n",
      "Valid ACC 0.6416015625\n",
      "EPOCH 4:\n",
      "LOSS train 0.6329618782227766 valid 0.6443570256233215\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 5:\n",
      "LOSS train 0.6280998735563129 valid 0.6560930609703064\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 6:\n",
      "LOSS train 0.622364157163505 valid 0.6683740615844727\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 7:\n",
      "LOSS train 0.6183679739000104 valid 0.6799067258834839\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 8:\n",
      "LOSS train 0.6137008293934748 valid 0.6899979114532471\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 9:\n",
      "LOSS train 0.6089891625422958 valid 0.697153627872467\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 10:\n",
      "LOSS train 0.6070030002940631 valid 0.7009488344192505\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 11:\n",
      "LOSS train 0.6036130130713713 valid 0.7255898118019104\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 12:\n",
      "LOSS train 0.6093287187899258 valid 0.7354453206062317\n",
      "Valid ACC 0.6875\n",
      "EPOCH 13:\n",
      "LOSS train 0.5944719677064436 valid 0.751022219657898\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 14:\n",
      "LOSS train 0.597401685431494 valid 0.789236307144165\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 15:\n",
      "LOSS train 0.5962571952993988 valid 0.7949631214141846\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 16:\n",
      "LOSS train 0.5950881235354336 valid 0.7843253016471863\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 17:\n",
      "LOSS train 0.5865228298708056 valid 0.8216416239738464\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 18:\n",
      "LOSS train 0.5848322551935277 valid 0.7965072989463806\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 19:\n",
      "LOSS train 0.5828107185397587 valid 0.8979014754295349\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 20:\n",
      "LOSS train 0.5821032036914893 valid 0.9060308933258057\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 1:\n",
      "LOSS train 0.6816653672685015 valid 0.63970947265625\n",
      "Valid ACC 0.6875\n",
      "EPOCH 2:\n",
      "LOSS train 0.6307320808265227 valid 0.6530624628067017\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 3:\n",
      "LOSS train 0.6243864731162998 valid 0.6638681292533875\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 4:\n",
      "LOSS train 0.6185571821868843 valid 0.6804084777832031\n",
      "Valid ACC 0.6689453125\n",
      "EPOCH 5:\n",
      "LOSS train 0.616010012673148 valid 0.6695795059204102\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 6:\n",
      "LOSS train 0.60956564735859 valid 0.7012546062469482\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 7:\n",
      "LOSS train 0.611386147902367 valid 0.6910404562950134\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 8:\n",
      "LOSS train 0.6016608702798262 valid 0.7310192584991455\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 9:\n",
      "LOSS train 0.599456268316465 valid 0.7228978872299194\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 10:\n",
      "LOSS train 0.5965662470734712 valid 0.7637072205543518\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 11:\n",
      "LOSS train 0.5974078798759068 valid 0.7753909230232239\n",
      "Valid ACC 0.6669921875\n",
      "EPOCH 12:\n",
      "LOSS train 0.5938071308406532 valid 0.7687509655952454\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 13:\n",
      "LOSS train 0.5889321918605913 valid 0.8023561239242554\n",
      "Valid ACC 0.671875\n",
      "EPOCH 14:\n",
      "LOSS train 0.5836695332265069 valid 0.7950178384780884\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 15:\n",
      "LOSS train 0.5824306694962454 valid 0.8369615077972412\n",
      "Valid ACC 0.671875\n",
      "EPOCH 16:\n",
      "LOSS train 0.5801375245160245 valid 0.8235202431678772\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 17:\n",
      "LOSS train 0.5769254675148227 valid 0.8717224597930908\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 18:\n",
      "LOSS train 0.5769684296761844 valid 0.8606510162353516\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 19:\n",
      "LOSS train 0.5753448099320662 valid 0.879450798034668\n",
      "Valid ACC 0.6708984375\n",
      "EPOCH 20:\n",
      "LOSS train 0.570457212891139 valid 0.8837645649909973\n",
      "Valid ACC 0.671875\n",
      "EPOCH 1:\n",
      "LOSS train 0.6703087392639606 valid 0.6374807357788086\n",
      "Valid ACC 0.6875\n",
      "EPOCH 2:\n",
      "LOSS train 0.6130198229711952 valid 0.6329191327095032\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 3:\n",
      "LOSS train 0.6052015338172304 valid 0.6400308012962341\n",
      "Valid ACC 0.6875\n",
      "EPOCH 4:\n",
      "LOSS train 0.5995589079374962 valid 0.6533949971199036\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 5:\n",
      "LOSS train 0.5951836770730661 valid 0.6700225472450256\n",
      "Valid ACC 0.6875\n",
      "EPOCH 6:\n",
      "LOSS train 0.5917114056382619 valid 0.6727280616760254\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 7:\n",
      "LOSS train 0.590560701193539 valid 0.6779800057411194\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 8:\n",
      "LOSS train 0.5857360906212042 valid 0.6868444085121155\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 9:\n",
      "LOSS train 0.5806242962044181 valid 0.6977458596229553\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 10:\n",
      "LOSS train 0.5789806876622193 valid 0.7101075649261475\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 11:\n",
      "LOSS train 0.573219545027043 valid 0.7278490662574768\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 12:\n",
      "LOSS train 0.5705600099783417 valid 0.7363075017929077\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 13:\n",
      "LOSS train 0.5699656139662925 valid 0.7141707539558411\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 14:\n",
      "LOSS train 0.5667929023715621 valid 0.7258772253990173\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 15:\n",
      "LOSS train 0.5611050048618452 valid 0.7359088063240051\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 16:\n",
      "LOSS train 0.5555996681358797 valid 0.7410979866981506\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 17:\n",
      "LOSS train 0.5549677146453385 valid 0.7788293361663818\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 18:\n",
      "LOSS train 0.549095722906133 valid 0.862926185131073\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 19:\n",
      "LOSS train 0.5490751600434595 valid 0.8745110630989075\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 20:\n",
      "LOSS train 0.5479951464960761 valid 0.8777272701263428\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 1:\n",
      "LOSS train 0.6846552365426476 valid 0.7230976819992065\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 2:\n",
      "LOSS train 0.6229874098554571 valid 0.7307369709014893\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 3:\n",
      "LOSS train 0.6189886268149031 valid 0.739067792892456\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 4:\n",
      "LOSS train 0.6162849835892941 valid 0.7397525906562805\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6124245415553979 valid 0.7426633834838867\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 6:\n",
      "LOSS train 0.6449768590800306 valid 0.7617249488830566\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 7:\n",
      "LOSS train 0.6049232556887553 valid 0.7556967735290527\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 8:\n",
      "LOSS train 0.6005960619407342 valid 0.7746767401695251\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 9:\n",
      "LOSS train 0.5949543649000479 valid 0.8002173900604248\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 10:\n",
      "LOSS train 0.5904253521498214 valid 0.793811559677124\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 11:\n",
      "LOSS train 0.600601002468285 valid 0.8052842617034912\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 12:\n",
      "LOSS train 0.5834455996329058 valid 0.8545234203338623\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 13:\n",
      "LOSS train 0.5786558387550056 valid 0.8793959617614746\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 14:\n",
      "LOSS train 0.5736447064377738 valid 0.8676676750183105\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 15:\n",
      "LOSS train 0.5675437049874177 valid 0.891560971736908\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 16:\n",
      "LOSS train 0.5666208400371227 valid 0.9469072818756104\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 17:\n",
      "LOSS train 0.5642931821709829 valid 0.9274670481681824\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 18:\n",
      "LOSS train 0.5659614527690495 valid 0.8973374962806702\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 19:\n",
      "LOSS train 0.5595566675806722 valid 0.9437136650085449\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 20:\n",
      "LOSS train 0.55638598550296 valid 0.9627238512039185\n",
      "Valid ACC 0.6708984375\n",
      "EPOCH 1:\n",
      "LOSS train 0.6753304084987505 valid 0.6375688314437866\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 2:\n",
      "LOSS train 0.6226049870886701 valid 0.6567006707191467\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 3:\n",
      "LOSS train 0.6168608558727494 valid 0.6616339683532715\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 4:\n",
      "LOSS train 0.6100472719111341 valid 0.6735478639602661\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6050754122911616 valid 0.684076726436615\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 6:\n",
      "LOSS train 0.6010826707731748 valid 0.6966403722763062\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 7:\n",
      "LOSS train 0.5943897952001991 valid 0.7142531871795654\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 8:\n",
      "LOSS train 0.592352624586288 valid 0.7220216393470764\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 9:\n",
      "LOSS train 0.586908684343311 valid 0.7445324063301086\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 10:\n",
      "LOSS train 0.5848474152756076 valid 0.7773354053497314\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 11:\n",
      "LOSS train 0.5795835949850421 valid 0.7976720333099365\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 12:\n",
      "LOSS train 0.5775542409284741 valid 0.8144638538360596\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 13:\n",
      "LOSS train 0.5699086989282717 valid 0.8422530889511108\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 14:\n",
      "LOSS train 0.5709508831830735 valid 0.8469401597976685\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 15:\n",
      "LOSS train 0.5692178429441249 valid 0.8636435270309448\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 16:\n",
      "LOSS train 0.6215755792585671 valid 0.8670738339424133\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 17:\n",
      "LOSS train 0.6195738663276037 valid 0.8971647024154663\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 18:\n",
      "LOSS train 0.5636041431773638 valid 0.8704895973205566\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 19:\n",
      "LOSS train 0.5556586810671691 valid 0.888619601726532\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 20:\n",
      "LOSS train 0.5519614323233881 valid 0.8953754901885986\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 1:\n",
      "LOSS train 0.7149003356272448 valid 0.6380041241645813\n",
      "Valid ACC 0.6884765625\n",
      "EPOCH 2:\n",
      "LOSS train 0.6302946148611975 valid 0.6294013261795044\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 3:\n",
      "LOSS train 0.6161708342479476 valid 0.6302213668823242\n",
      "Valid ACC 0.6923828125\n",
      "EPOCH 4:\n",
      "LOSS train 0.6107678451436631 valid 0.6358665823936462\n",
      "Valid ACC 0.6923828125\n",
      "EPOCH 5:\n",
      "LOSS train 0.6060799085502083 valid 0.6490491032600403\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 6:\n",
      "LOSS train 0.5994545043782985 valid 0.6630906462669373\n",
      "Valid ACC 0.6845703125\n",
      "EPOCH 7:\n",
      "LOSS train 0.5968474068328844 valid 0.6663824915885925\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 8:\n",
      "LOSS train 0.5917161740098439 valid 0.6967507600784302\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 9:\n",
      "LOSS train 0.5885812845213193 valid 0.6723130941390991\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 10:\n",
      "LOSS train 0.5848322172536917 valid 0.7029750943183899\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 11:\n",
      "LOSS train 0.5821377124558104 valid 0.720028281211853\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 12:\n",
      "LOSS train 0.5984018757833657 valid 0.7395626306533813\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 13:\n",
      "LOSS train 0.5732149899217254 valid 0.7290394306182861\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 14:\n",
      "LOSS train 0.5707265748411205 valid 0.7458073496818542\n",
      "Valid ACC 0.689453125\n",
      "EPOCH 15:\n",
      "LOSS train 0.5653268508877315 valid 0.7610918879508972\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 16:\n",
      "LOSS train 0.5715202224170063 valid 0.7851141095161438\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 17:\n",
      "LOSS train 0.5623367167745076 valid 0.7561944723129272\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 18:\n",
      "LOSS train 0.55228217368853 valid 0.8970137238502502\n",
      "Valid ACC 0.681640625\n",
      "EPOCH 19:\n",
      "LOSS train 0.5537770144271512 valid 0.8089844584465027\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 20:\n",
      "LOSS train 0.5509092611201266 valid 0.854133665561676\n",
      "Valid ACC 0.6728515625\n",
      "EPOCH 1:\n",
      "LOSS train 0.686136319070843 valid 0.7247138023376465\n",
      "Valid ACC 0.6875\n",
      "EPOCH 2:\n",
      "LOSS train 0.6153089270946828 valid 0.7244715094566345\n",
      "Valid ACC 0.6865234375\n",
      "EPOCH 3:\n",
      "LOSS train 0.610455296035354 valid 0.7273077964782715\n",
      "Valid ACC 0.6875\n",
      "EPOCH 4:\n",
      "LOSS train 0.6070895209802804 valid 0.729430615901947\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6030604709336098 valid 0.7309724688529968\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 6:\n",
      "LOSS train 0.5988046517397495 valid 0.7325665950775146\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 7:\n",
      "LOSS train 0.5953426208901913 valid 0.7384181618690491\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 8:\n",
      "LOSS train 0.5911767474303009 valid 0.7567570805549622\n",
      "Valid ACC 0.671875\n",
      "EPOCH 9:\n",
      "LOSS train 0.6077197886316489 valid 0.7412219643592834\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 10:\n",
      "LOSS train 0.5845641283490134 valid 0.7497023344039917\n",
      "Valid ACC 0.67578125\n",
      "EPOCH 11:\n",
      "LOSS train 0.5815473530732148 valid 0.7526775598526001\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 12:\n",
      "LOSS train 0.5755642293192816 valid 0.7586595416069031\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 13:\n",
      "LOSS train 0.5717885862005517 valid 0.7678433656692505\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 14:\n",
      "LOSS train 0.5673819282587539 valid 0.7705589532852173\n",
      "Valid ACC 0.6826171875\n",
      "EPOCH 15:\n",
      "LOSS train 0.565161738201236 valid 0.7952896952629089\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 16:\n",
      "LOSS train 0.5600605613373696 valid 0.7987254858016968\n",
      "Valid ACC 0.685546875\n",
      "EPOCH 17:\n",
      "LOSS train 0.5607544248197096 valid 0.7927080392837524\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 18:\n",
      "LOSS train 0.5562862129287517 valid 0.8136644959449768\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 19:\n",
      "LOSS train 0.5528763842286794 valid 0.8379086852073669\n",
      "Valid ACC 0.6650390625\n",
      "EPOCH 20:\n",
      "LOSS train 0.5595458974229529 valid 0.8282420039176941\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 1:\n",
      "LOSS train 0.6631861620760978 valid 0.6500769853591919\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 2:\n",
      "LOSS train 0.6239040155782767 valid 0.6545225381851196\n",
      "Valid ACC 0.6796875\n",
      "EPOCH 3:\n",
      "LOSS train 0.6150239576050576 valid 0.6563277244567871\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 4:\n",
      "LOSS train 0.6086713614615988 valid 0.6746211647987366\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 5:\n",
      "LOSS train 0.6046391506778434 valid 0.662082850933075\n",
      "Valid ACC 0.6787109375\n",
      "EPOCH 6:\n",
      "LOSS train 0.6056803048502469 valid 0.6752660274505615\n",
      "Valid ACC 0.68359375\n",
      "EPOCH 7:\n",
      "LOSS train 0.5973131231805111 valid 0.7789638042449951\n",
      "Valid ACC 0.673828125\n",
      "EPOCH 8:\n",
      "LOSS train 0.594996636640941 valid 0.7839021682739258\n",
      "Valid ACC 0.677734375\n",
      "EPOCH 9:\n",
      "LOSS train 0.5898806734922084 valid 0.702990710735321\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 10:\n",
      "LOSS train 0.5839944624520362 valid 0.8107761740684509\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 11:\n",
      "LOSS train 0.5831166066176502 valid 0.7462899684906006\n",
      "Valid ACC 0.6611328125\n",
      "EPOCH 12:\n",
      "LOSS train 0.6041799131648761 valid 0.7487635612487793\n",
      "Valid ACC 0.6806640625\n",
      "EPOCH 13:\n",
      "LOSS train 0.5793997022911166 valid 0.8426578044891357\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 14:\n",
      "LOSS train 0.5735041643922211 valid 0.7547245621681213\n",
      "Valid ACC 0.6748046875\n",
      "EPOCH 15:\n",
      "LOSS train 0.5692346026288703 valid 0.8661837577819824\n",
      "Valid ACC 0.6669921875\n",
      "EPOCH 16:\n",
      "LOSS train 0.5715143820072742 valid 0.8526099324226379\n",
      "Valid ACC 0.6767578125\n",
      "EPOCH 17:\n",
      "LOSS train 0.5663790940604312 valid 0.8874017000198364\n",
      "Valid ACC 0.66796875\n",
      "EPOCH 18:\n",
      "LOSS train 0.5620091525798149 valid 0.8788856863975525\n",
      "Valid ACC 0.6689453125\n",
      "EPOCH 19:\n",
      "LOSS train 0.5605209109419627 valid 0.9000780582427979\n",
      "Valid ACC 0.669921875\n",
      "EPOCH 20:\n",
      "LOSS train 0.6473400551587978 valid 0.9111533164978027\n",
      "Valid ACC 0.669921875\n",
      "[(tensor(0.6293, device='cuda:0'), tensor(0.6895, device='cuda:0'), 0, 5), (tensor(0.6405, device='cuda:0'), tensor(0.6816, device='cuda:0'), 0, 2), (tensor(0.6618, device='cuda:0'), tensor(0.6836, device='cuda:0'), 4, 1), (tensor(0.6674, device='cuda:0'), tensor(0.6787, device='cuda:0'), 9, 0), (tensor(0.8309, device='cuda:0'), tensor(0.6914, device='cuda:0'), 8, 0), (tensor(1.2128, device='cuda:0'), tensor(0.6875, device='cuda:0'), 3, 0), (tensor(1.2456, device='cuda:0'), tensor(0.6904, device='cuda:0'), 2, 0), (tensor(1.3699, device='cuda:0'), tensor(0.6865, device='cuda:0'), 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "model_path = None\n",
    "\n",
    "total_layers = hiddens.size(0)\n",
    "results = []\n",
    "for layer_num in range(total_layers):\n",
    "    writer = SummaryWriter(f'runs/hiddens_layer_{layer_num}')\n",
    "    train_x, val_x, train_y,val_y = train_test_split(hiddens[layer_num],labels,test_size=0.1,random_state=42,stratify=labels)\n",
    "    training_loader = torch.utils.data.DataLoader(list(zip(train_x,train_y)), batch_size=32, shuffle=True)\n",
    "    validation_loader = torch.utils.data.DataLoader(list(zip(val_x,val_y)), batch_size=32, shuffle=False)\n",
    "\n",
    "    for epoch_number in range(EPOCHS):\n",
    "        print(f'EPOCH {epoch_number+1}:')\n",
    "\n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        classifier.train(True)\n",
    "        avg_loss = train_one_epoch(epoch_number,training_loader)\n",
    "\n",
    "        running_vloss = 0.0\n",
    "        running_vacc = 0.0\n",
    "\n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                vinputs= vinputs.to(device)\n",
    "                vlabels = vlabels.unsqueeze(1).float().to(device)\n",
    "\n",
    "                voutputs = classifier(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "                running_vacc += (voutputs.round() == vlabels).float().mean()\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        avg_acc = running_vacc / (i+1)\n",
    "        print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "        print(f'Valid ACC {avg_acc}')\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.add_scalars('Validation accuracy',\n",
    "                        { 'ACC' : avg_acc},\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss    \n",
    "            model_path = f'model_{epoch_number}_{best_vloss}'\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "            results.append((best_vloss,avg_acc,epoch_number,layer_num))\n",
    "\n",
    "\n",
    "        epoch_number += 1\n",
    "print(list(sorted(results,key=lambda x:x[0]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.6293, device='cuda:0'), tensor(0.6895, device='cuda:0'), 0, 5),\n",
       " (tensor(0.6405, device='cuda:0'), tensor(0.6816, device='cuda:0'), 0, 2),\n",
       " (tensor(0.6618, device='cuda:0'), tensor(0.6836, device='cuda:0'), 4, 1),\n",
       " (tensor(0.6674, device='cuda:0'), tensor(0.6787, device='cuda:0'), 9, 0),\n",
       " (tensor(0.8309, device='cuda:0'), tensor(0.6914, device='cuda:0'), 8, 0),\n",
       " (tensor(1.2128, device='cuda:0'), tensor(0.6875, device='cuda:0'), 3, 0),\n",
       " (tensor(1.2456, device='cuda:0'), tensor(0.6904, device='cuda:0'), 2, 0),\n",
       " (tensor(1.3699, device='cuda:0'), tensor(0.6865, device='cuda:0'), 0, 0)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(results,key=lambda x:x[0]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
