{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
    "import pandas as pd\n",
    "from bertviz import head_view\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dev = \"../data/labeled-train.model-aware.v2.json\"\n",
    "df = pd.read_json(path_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 564/564 [00:00<00:00, 312kB/s]\n",
      "sentencepiece.bpe.model: 100%|██████████| 4.85M/4.85M [00:00<00:00, 12.9MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.3M/17.3M [00:01<00:00, 9.36MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 3.55k/3.55k [00:00<00:00, 20.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'Separation and reintegration continue to shift the differences between the two pools with each generation.',\n",
       " 'ref': 'either',\n",
       " 'src': 'अलगाव आ पुनर्संयोजन प्रत्येक पीढ़ीक संग द्विटा पूल सभक बीच फेरबदल भिन्नता कें आगू-पाछू करैत रहैत अछि।',\n",
       " 'tgt': 'Segregation and recombination shuffle variation back and forth between the two pools with each generation.',\n",
       " 'model': 'facebook/nllb-200-distilled-600M',\n",
       " 'task': 'MT',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Hallucination'],\n",
       " 'label': 'Hallucination',\n",
       " 'p(Hallucination)': 0.6000000000000001}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"task\"] == \"MT\"].iloc[2].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'अलगाव आ पुनर्संयोजन प्रत्येक पीढ़ीक संग द्विटा पूल सभक बीच फेरबदल भिन्नता कें आगू-पाछू करैत रहैत अछि।'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = df[df[\"task\"] == \"\"].iloc[2][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from one generation to the next.</s><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from one generation to the next.</s>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools with each generation.</s><pad><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from generation to generation.</s><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from generation to generation.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools with each generation.</s><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a significant difference between the two pools from generation to generation.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a difference between the two pools from one generation to another.</s><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continue to bring about change between the two pools with each generation.</s><pad><pad><pad><pad>',\n",
       " '</s>eng_Latn Separation and reintegration continues to make a distinction between the two pools from one generation to another.</s><pad>']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(**tokens, \n",
    "                         forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"],\n",
    "                         num_beams=10,\n",
    "                         do_sample=True,\n",
    "                         num_return_sequences=1)\n",
    "text = tokenizer.batch_decode(outputs)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>labels</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sloping top .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The sides of the casket were covered with heav...</td>\n",
       "      <td>A decorative feature that sits on top of somet...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To react too much .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please try not to overreact if she drives badl...</td>\n",
       "      <td>To react too much or too intensely .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Not Hallucination, Not Hal...</td>\n",
       "      <td>Not Hallucination</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The process of spoiling ; the state of being s...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To prevent spoilage , store in a cool , dry pl...</td>\n",
       "      <td>The process of spoiling .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To arrange in a particular way .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The way the opposition has framed the argument...</td>\n",
       "      <td>To construct in words so as to establish a con...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A feeling of concern ; a feeling of anxiety .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To mix with thy concernments i desist . What i...</td>\n",
       "      <td>That in which one is concerned or interested ;...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Of or pertaining to communism .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Communistic birds . What is the meaning of com...</td>\n",
       "      <td>Living or having their nests in common .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The act of treating a disease or condition .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Lahmann 's unprecedented success proved beyond...</td>\n",
       "      <td>Attempted remediation of a health problem foll...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Able to be collected .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>He 's owed it to us for six months , but it do...</td>\n",
       "      <td>That is likely to be paid .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Not Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>A native or inhabitant of the us state of uson...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>As a usonian of celtic-franco/gallego mexican-...</td>\n",
       "      <td>An inhabitant or citizen of the United States ...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A loan .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please do me a solid : lend me your car for on...</td>\n",
       "      <td>A favor .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hyp  ref  \\\n",
       "0                                      A sloping top .  tgt   \n",
       "1                                  To react too much .  tgt   \n",
       "2    The process of spoiling ; the state of being s...  tgt   \n",
       "3                     To arrange in a particular way .  tgt   \n",
       "4        A feeling of concern ; a feeling of anxiety .  tgt   \n",
       "..                                                 ...  ...   \n",
       "183                    Of or pertaining to communism .  tgt   \n",
       "184       The act of treating a disease or condition .  tgt   \n",
       "185                             Able to be collected .  tgt   \n",
       "186  A native or inhabitant of the us state of uson...  tgt   \n",
       "187                                           A loan .  tgt   \n",
       "\n",
       "                                                   src  \\\n",
       "0    The sides of the casket were covered with heav...   \n",
       "1    Please try not to overreact if she drives badl...   \n",
       "2    To prevent spoilage , store in a cool , dry pl...   \n",
       "3    The way the opposition has framed the argument...   \n",
       "4    To mix with thy concernments i desist . What i...   \n",
       "..                                                 ...   \n",
       "183  Communistic birds . What is the meaning of com...   \n",
       "184  Lahmann 's unprecedented success proved beyond...   \n",
       "185  He 's owed it to us for six months , but it do...   \n",
       "186  As a usonian of celtic-franco/gallego mexican-...   \n",
       "187  Please do me a solid : lend me your car for on...   \n",
       "\n",
       "                                                   tgt  \\\n",
       "0    A decorative feature that sits on top of somet...   \n",
       "1                 To react too much or too intensely .   \n",
       "2                            The process of spoiling .   \n",
       "3    To construct in words so as to establish a con...   \n",
       "4    That in which one is concerned or interested ;...   \n",
       "..                                                 ...   \n",
       "183           Living or having their nests in common .   \n",
       "184  Attempted remediation of a health problem foll...   \n",
       "185                        That is likely to be paid .   \n",
       "186  An inhabitant or citizen of the United States ...   \n",
       "187                                          A favor .   \n",
       "\n",
       "                              model task  \\\n",
       "0    ltg/flan-t5-definition-en-base   DM   \n",
       "1    ltg/flan-t5-definition-en-base   DM   \n",
       "2    ltg/flan-t5-definition-en-base   DM   \n",
       "3    ltg/flan-t5-definition-en-base   DM   \n",
       "4    ltg/flan-t5-definition-en-base   DM   \n",
       "..                              ...  ...   \n",
       "183  ltg/flan-t5-definition-en-base   DM   \n",
       "184  ltg/flan-t5-definition-en-base   DM   \n",
       "185  ltg/flan-t5-definition-en-base   DM   \n",
       "186  ltg/flan-t5-definition-en-base   DM   \n",
       "187  ltg/flan-t5-definition-en-base   DM   \n",
       "\n",
       "                                                labels              label  \\\n",
       "0    [Not Hallucination, Hallucination, Not Halluci...      Hallucination   \n",
       "1    [Not Hallucination, Not Hallucination, Not Hal...  Not Hallucination   \n",
       "2    [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "3    [Hallucination, Not Hallucination, Not Halluci...      Hallucination   \n",
       "4    [Not Hallucination, Hallucination, Hallucinati...      Hallucination   \n",
       "..                                                 ...                ...   \n",
       "183  [Hallucination, Hallucination, Hallucination, ...      Hallucination   \n",
       "184  [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "185  [Hallucination, Hallucination, Not Hallucinati...      Hallucination   \n",
       "186  [Hallucination, Hallucination, Hallucination, ...      Hallucination   \n",
       "187  [Hallucination, Not Hallucination, Hallucinati...      Hallucination   \n",
       "\n",
       "     p(Hallucination)  \n",
       "0                 0.6  \n",
       "1                 0.0  \n",
       "2                 0.6  \n",
       "3                 0.6  \n",
       "4                 0.6  \n",
       "..                ...  \n",
       "183               1.0  \n",
       "184               0.6  \n",
       "185               0.8  \n",
       "186               1.0  \n",
       "187               0.8  \n",
       "\n",
       "[188 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"task\"] == \"DM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ltg/flan-t5-definition-en-base\",output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ltg/flan-t5-definition-en-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>labels</th>\n",
       "      <th>label</th>\n",
       "      <th>p(Hallucination)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A sloping top .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The sides of the casket were covered with heav...</td>\n",
       "      <td>A decorative feature that sits on top of somet...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The process of spoiling ; the state of being s...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To prevent spoilage , store in a cool , dry pl...</td>\n",
       "      <td>The process of spoiling .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To arrange in a particular way .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>The way the opposition has framed the argument...</td>\n",
       "      <td>To construct in words so as to establish a con...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Not Halluci...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A feeling of concern ; a feeling of anxiety .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>To mix with thy concernments i desist . What i...</td>\n",
       "      <td>That in which one is concerned or interested ;...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Not Hallucination, Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To suffocate .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Having divested the child he kissed her gently...</td>\n",
       "      <td>To undress .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Of or pertaining to communism .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Communistic birds . What is the meaning of com...</td>\n",
       "      <td>Living or having their nests in common .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>The act of treating a disease or condition .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Lahmann 's unprecedented success proved beyond...</td>\n",
       "      <td>Attempted remediation of a health problem foll...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Able to be collected .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>He 's owed it to us for six months , but it do...</td>\n",
       "      <td>That is likely to be paid .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Not Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>A native or inhabitant of the us state of uson...</td>\n",
       "      <td>tgt</td>\n",
       "      <td>As a usonian of celtic-franco/gallego mexican-...</td>\n",
       "      <td>An inhabitant or citizen of the United States ...</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Hallucination, Hallucination, ...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A loan .</td>\n",
       "      <td>tgt</td>\n",
       "      <td>Please do me a solid : lend me your car for on...</td>\n",
       "      <td>A favor .</td>\n",
       "      <td>ltg/flan-t5-definition-en-base</td>\n",
       "      <td>DM</td>\n",
       "      <td>[Hallucination, Not Hallucination, Hallucinati...</td>\n",
       "      <td>Hallucination</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hyp  ref  \\\n",
       "0                                      A sloping top .  tgt   \n",
       "2    The process of spoiling ; the state of being s...  tgt   \n",
       "3                     To arrange in a particular way .  tgt   \n",
       "4        A feeling of concern ; a feeling of anxiety .  tgt   \n",
       "6                                       To suffocate .  tgt   \n",
       "..                                                 ...  ...   \n",
       "183                    Of or pertaining to communism .  tgt   \n",
       "184       The act of treating a disease or condition .  tgt   \n",
       "185                             Able to be collected .  tgt   \n",
       "186  A native or inhabitant of the us state of uson...  tgt   \n",
       "187                                           A loan .  tgt   \n",
       "\n",
       "                                                   src  \\\n",
       "0    The sides of the casket were covered with heav...   \n",
       "2    To prevent spoilage , store in a cool , dry pl...   \n",
       "3    The way the opposition has framed the argument...   \n",
       "4    To mix with thy concernments i desist . What i...   \n",
       "6    Having divested the child he kissed her gently...   \n",
       "..                                                 ...   \n",
       "183  Communistic birds . What is the meaning of com...   \n",
       "184  Lahmann 's unprecedented success proved beyond...   \n",
       "185  He 's owed it to us for six months , but it do...   \n",
       "186  As a usonian of celtic-franco/gallego mexican-...   \n",
       "187  Please do me a solid : lend me your car for on...   \n",
       "\n",
       "                                                   tgt  \\\n",
       "0    A decorative feature that sits on top of somet...   \n",
       "2                            The process of spoiling .   \n",
       "3    To construct in words so as to establish a con...   \n",
       "4    That in which one is concerned or interested ;...   \n",
       "6                                         To undress .   \n",
       "..                                                 ...   \n",
       "183           Living or having their nests in common .   \n",
       "184  Attempted remediation of a health problem foll...   \n",
       "185                        That is likely to be paid .   \n",
       "186  An inhabitant or citizen of the United States ...   \n",
       "187                                          A favor .   \n",
       "\n",
       "                              model task  \\\n",
       "0    ltg/flan-t5-definition-en-base   DM   \n",
       "2    ltg/flan-t5-definition-en-base   DM   \n",
       "3    ltg/flan-t5-definition-en-base   DM   \n",
       "4    ltg/flan-t5-definition-en-base   DM   \n",
       "6    ltg/flan-t5-definition-en-base   DM   \n",
       "..                              ...  ...   \n",
       "183  ltg/flan-t5-definition-en-base   DM   \n",
       "184  ltg/flan-t5-definition-en-base   DM   \n",
       "185  ltg/flan-t5-definition-en-base   DM   \n",
       "186  ltg/flan-t5-definition-en-base   DM   \n",
       "187  ltg/flan-t5-definition-en-base   DM   \n",
       "\n",
       "                                                labels          label  \\\n",
       "0    [Not Hallucination, Hallucination, Not Halluci...  Hallucination   \n",
       "2    [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "3    [Hallucination, Not Hallucination, Not Halluci...  Hallucination   \n",
       "4    [Not Hallucination, Hallucination, Hallucinati...  Hallucination   \n",
       "6    [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "..                                                 ...            ...   \n",
       "183  [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "184  [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "185  [Hallucination, Hallucination, Not Hallucinati...  Hallucination   \n",
       "186  [Hallucination, Hallucination, Hallucination, ...  Hallucination   \n",
       "187  [Hallucination, Not Hallucination, Hallucinati...  Hallucination   \n",
       "\n",
       "     p(Hallucination)  \n",
       "0                 0.6  \n",
       "2                 0.6  \n",
       "3                 0.6  \n",
       "4                 0.6  \n",
       "6                 1.0  \n",
       "..                ...  \n",
       "183               1.0  \n",
       "184               0.6  \n",
       "185               0.8  \n",
       "186               1.0  \n",
       "187               0.8  \n",
       "\n",
       "[89 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_hal = df[(df[\"task\"] == \"DM\") & (df[\"label\"] == \"Hallucination\")]\n",
    "dm_hal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing positive example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'To suffocate .',\n",
       " 'ref': 'tgt',\n",
       " 'src': 'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?',\n",
       " 'tgt': 'To undress .',\n",
       " 'model': 'ltg/flan-t5-definition-en-base',\n",
       " 'task': 'DM',\n",
       " 'labels': ['Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination',\n",
       "  'Hallucination'],\n",
       " 'label': 'Hallucination',\n",
       " 'p(Hallucination)': 1.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
    "decoder_tokens = tokenizer.convert_ids_to_tokens(outputs.sequences[0])\n",
    "\n",
    "result = model(input_ids=tokens[\"input_ids\"],decoder_input_ids=outputs.sequences, use_cache=False,                \n",
    "        output_attentions=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(\n",
    "    encoder_attention=result.encoder_attentions,\n",
    "    decoder_attention=result.decoder_attentions,\n",
    "    cross_attention=result.cross_attentions,\n",
    "    encoder_tokens= encoder_tokens,\n",
    "    decoder_tokens = decoder_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing negative example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': 'To react too much .',\n",
       " 'ref': 'tgt',\n",
       " 'src': 'Please try not to overreact if she drives badly when she is first learning . What is the meaning of overreact ?',\n",
       " 'tgt': 'To react too much or too intensely .',\n",
       " 'model': 'ltg/flan-t5-definition-en-base',\n",
       " 'task': 'DM',\n",
       " 'labels': ['Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination',\n",
       "  'Not Hallucination'],\n",
       " 'label': 'Not Hallucination',\n",
       " 'p(Hallucination)': 0.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")].iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please try not to overreact if she drives badly when she is first learning . What is the meaning of overreact ?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")].iloc[0][\"src\"]\n",
    "src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_tokens = tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n",
    "decoder_tokens = tokenizer.convert_ids_to_tokens(outputs.sequences[0])\n",
    "\n",
    "result = model(input_ids=tokens[\"input_ids\"],decoder_input_ids=outputs.sequences, use_cache=False,                \n",
    "        output_attentions=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_view(\n",
    "    encoder_attention=result.encoder_attentions,\n",
    "    decoder_attention=result.decoder_attentions,\n",
    "    cross_attention=result.cross_attentions,\n",
    "    encoder_tokens= encoder_tokens,\n",
    "    decoder_tokens = decoder_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq-Logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Having divested the child he kissed her gently and gave her a little pat to make her stand off . What is the meaning of divest ?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = dm_hal[dm_hal[\"p(Hallucination)\"] == 1].iloc[0][\"src\"]\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(src,return_tensors=\"pt\")\n",
    "outputs = model.generate(**tokens,\n",
    "                         return_dict_in_generate=True,\n",
    "                         output_scores=True,\n",
    "                         output_attentions=True,\n",
    "                         output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '▁To', '▁', 's', 'uff', 'o', 'cate', '▁', '.', '</s>']\n",
      "<pad> To suffocate.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(outputs.sequences[0]))\n",
    "print(tokenizer.decode(outputs.sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_score(outputs):\n",
    "    max_logprobs = [score.max() for score in outputs.scores]\n",
    "    conf_score = sum(max_logprobs) / len(max_logprobs)\n",
    "    return conf_score\n",
    "\n",
    "def generate(source):\n",
    "    tokens = tokenizer(source,return_tensors=\"pt\")\n",
    "    outputs = model.generate(**tokens,\n",
    "                            return_dict_in_generate=True,\n",
    "                            output_scores=True,)\n",
    "    return get_conf_score(outputs)\n",
    "\n",
    "def get_token_lengths(sequences):\n",
    "    tok_lens = []\n",
    "    for seq in sequences:\n",
    "        toks = tokenizer.convert_ids_to_tokens(seq,skip_special_tokens=True)\n",
    "        tok_lens.append(len(toks))\n",
    "    return torch.tensor(tok_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = dm_hal[dm_hal[\"p(Hallucination)\"] == 1][\"src\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilyalasy/miniconda3/envs/lm/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(srcs,return_tensors=\"pt\",padding=True,truncation=True)\n",
    "outputs = model.generate(**tokens,\n",
    "                        return_dict_in_generate=True,\n",
    "                        output_scores=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.4071,  5.3401, -0.2419,  0.8012,  5.9969,  4.8076,  4.0492,  3.5485,\n",
       "         6.0472,  4.6019,  6.1943,  4.1186,  7.5194,  5.5130,  3.0846,  4.9129,\n",
       "         4.3745,  4.8689,  3.2190,  7.8033, 10.2741,  7.3097,  4.6601,  7.4027,\n",
       "         6.3553,  3.5634,  5.4295, 10.4581,  5.3850,  8.9073,  6.4095,  4.3153,\n",
       "         6.9461,  5.1326,  4.2383])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lens = get_token_lengths(outputs.sequences)\n",
    "#TODO: don't include conf scores from pad tokens\n",
    "conf_scores = torch.stack([torch.max(score,dim=1).values for score in outputs.scores]).sum(0)  / tok_lens\n",
    "conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2419)\n",
      "tensor(10.4581)\n"
     ]
    }
   ],
   "source": [
    "print(conf_scores.min())\n",
    "print(conf_scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = df[(df[\"p(Hallucination)\"] == 0) & (df[\"task\"] == \"DM\")][\"src\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(srcs,return_tensors=\"pt\",padding=True,truncation=True)\n",
    "outputs = model.generate(**tokens,\n",
    "                        return_dict_in_generate=True,\n",
    "                        output_scores=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.4396,  3.7341,  5.8660,  4.8929,  2.1771, 13.0546,  8.6266,  4.7140,\n",
       "         3.3716,  5.6011, 17.0202,  5.0676,  4.2212, 11.1073,  4.7932,  6.5653,\n",
       "        24.7344,  5.5094,  7.6758,  6.1724,  3.6417,  5.7009,  8.1423, 13.5789,\n",
       "         6.1132,  7.8263, 32.1291,  5.4459,  4.7539,  4.6217,  6.5457])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lens = get_token_lengths(outputs.sequences)\n",
    "conf_scores = torch.stack([torch.max(score,dim=1).values for score in outputs.scores]).sum(0) / tok_lens\n",
    "conf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1771)\n",
      "tensor(32.1291)\n"
     ]
    }
   ],
   "source": [
    "print(conf_scores.min())\n",
    "print(conf_scores.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden States Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"DM\"\n",
    "FILTER = False\n",
    "\n",
    "task_df = df[(df[\"task\"] == TASK)] \n",
    "model_name = task_df[\"model\"].unique().item()\n",
    "if FILTER:\n",
    "    task_df = task_df[(task_df[\"p(Hallucination)\"] == 0) | (task_df[\"p(Hallucination)\"]==1)]\n",
    "task_df = task_df[[\"src\",\"label\"]]\n",
    "task_df[\"label\"] = task_df[\"label\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Check that MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = \"mps\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # turned out to be the best size, larger ones result in worse detections\n",
    "batched_df = [task_df[i:i+batch_size] for i in range(0,len(task_df),batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(outputs):\n",
    "    eos_indices = []\n",
    "    for seq in outputs.sequences:\n",
    "        nonzero = (seq == tokenizer.eos_token_id).nonzero()\n",
    "        if nonzero.nelement() != 0:\n",
    "            idx = nonzero.item()\n",
    "        else:\n",
    "            idx = seq.size(0)-1 #last token\n",
    "        eos_indices.append(idx-1) #skip first pad token    \n",
    "    eos_indices = torch.tensor(eos_indices,device=device)\n",
    "\n",
    "    decoder_hidden_states = []\n",
    "    for t in outputs.decoder_hidden_states:\n",
    "        decoder_hidden_states.append(torch.stack(t))\n",
    "    decoder_hidden_states = torch.stack(decoder_hidden_states)\n",
    "    seq_len,layers,batch, _, hidden_dim = decoder_hidden_states.size()\n",
    "    decoder_hidden_states = decoder_hidden_states.reshape((layers,batch,seq_len,-1))\n",
    "\n",
    "    eos_indices = eos_indices.reshape((1,-1,1,1)).repeat(layers,1,1,hidden_dim)\n",
    "    hiddens = decoder_hidden_states.gather(dim=2,index=eos_indices).squeeze(2)\n",
    "    return hiddens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [10:40<00:00,  7.91s/it]\n"
     ]
    }
   ],
   "source": [
    "start_batch = 0\n",
    "dataset = []\n",
    "for batch in tqdm.tqdm(batched_df[start_batch:],total=len(batched_df[start_batch:])):\n",
    "    tokens = tokenizer(batch[\"src\"].to_list(),\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**tokens,\n",
    "                                max_new_tokens=25,\n",
    "                                return_dict_in_generate=True,\n",
    "                                output_hidden_states=True)\n",
    "    hiddens = get_hidden_states(outputs)\n",
    "    dataset.append((hiddens.to(\"cpu\"),batch[\"label\"].cat.codes.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens,labels = list(zip(*dataset))\n",
    "hiddens = torch.cat(hiddens,dim=1)\n",
    "labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hidden.pkl\", \"wb\") as f:\n",
    "    pickle.dump((hiddens,labels),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0 # Experiment which decoder layers gives best results\n",
    "train_x, val_x, train_y,val_y = train_test_split(hiddens[layer_num],labels,test_size=0.1,random_state=42,stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(list(zip(train_x,train_y)), batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(list(zip(val_x,val_y)), batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = hiddens.size(-1)\n",
    "class StatesClassifier(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.Linear(hidden_dim,256)\n",
    "        self.ln2 = nn.Linear(256,128)\n",
    "        self.ln3 = nn.Linear(128,64)\n",
    "        self.head = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x).relu()\n",
    "        x = self.ln2(x).relu()\n",
    "        x = self.ln3(x).relu()\n",
    "        return self.head(x).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = StatesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    \n",
    "    for i, data in enumerate(training_loader):        \n",
    "        inputs, labels = data\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = classifier(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 13.130729471354984 valid 12.009413719177246\n",
      "Valid ACC 0.6333333253860474\n",
      "EPOCH 2:\n",
      "LOSS train 11.149714802240217 valid 6.690027713775635\n",
      "Valid ACC 0.6333333253860474\n",
      "EPOCH 3:\n",
      "LOSS train 5.3485969065666215 valid 1.9531974792480469\n",
      "Valid ACC 0.5666666626930237\n",
      "EPOCH 4:\n",
      "LOSS train 10.048405108280306 valid 3.028233766555786\n",
      "Valid ACC 0.5\n",
      "EPOCH 5:\n",
      "LOSS train 2.476804038466409 valid 2.3246378898620605\n",
      "Valid ACC 0.5\n",
      "EPOCH 6:\n",
      "LOSS train 0.9143225564513096 valid 0.7048738598823547\n",
      "Valid ACC 0.6166666746139526\n",
      "EPOCH 7:\n",
      "LOSS train 1.6165024055991062 valid 1.4431127309799194\n",
      "Valid ACC 0.6833333373069763\n",
      "EPOCH 8:\n",
      "LOSS train 1.0212282245643003 valid 1.0743036270141602\n",
      "Valid ACC 0.6833333373069763\n",
      "EPOCH 9:\n",
      "LOSS train 0.7735620986583621 valid 1.2093181610107422\n",
      "Valid ACC 0.6166666746139526\n",
      "EPOCH 10:\n",
      "LOSS train 0.7343074010555134 valid 1.3806054592132568\n",
      "Valid ACC 0.6166666746139526\n",
      "EPOCH 11:\n",
      "LOSS train 3.9626718918944515 valid 1.8516734838485718\n",
      "Valid ACC 0.5666666626930237\n",
      "EPOCH 12:\n",
      "LOSS train 0.6549573348142034 valid 1.2520471811294556\n",
      "Valid ACC 0.5\n",
      "EPOCH 13:\n",
      "LOSS train 0.5815546045406061 valid 0.9191195368766785\n",
      "Valid ACC 0.6166666746139526\n",
      "EPOCH 14:\n",
      "LOSS train 1.0099052816282872 valid 1.9366166591644287\n",
      "Valid ACC 0.550000011920929\n",
      "EPOCH 15:\n",
      "LOSS train 3.814619660550772 valid 10.457338333129883\n",
      "Valid ACC 0.6833333373069763\n",
      "EPOCH 16:\n",
      "LOSS train 3.928041688012241 valid 1.908827543258667\n",
      "Valid ACC 0.550000011920929\n",
      "EPOCH 17:\n",
      "LOSS train 0.541339239642311 valid 1.87752366065979\n",
      "Valid ACC 0.5166666507720947\n",
      "EPOCH 18:\n",
      "LOSS train 0.6179693117304597 valid 1.3130550384521484\n",
      "Valid ACC 0.6833333373069763\n",
      "EPOCH 19:\n",
      "LOSS train 1.0809467125164216 valid 1.2380115985870361\n",
      "Valid ACC 0.6833333373069763\n",
      "EPOCH 20:\n",
      "LOSS train 0.5506835591650723 valid 1.8371565341949463\n",
      "Valid ACC 0.6833333373069763\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "writer = None\n",
    "for epoch_number in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch_number+1}:')\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    classifier.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    running_vacc = 0.0\n",
    "\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vlabels = vlabels.unsqueeze(1).float()\n",
    "            voutputs = classifier(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            running_vacc += (voutputs.round() == vlabels).float().mean()\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    avg_acc = running_vacc / (i+1)\n",
    "    print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "    print(f'Valid ACC {avg_acc}')\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    # writer.add_scalars('Training vs. Validation Loss',\n",
    "    #                 { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "    #                 epoch_number + 1)\n",
    "    # writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    # if avg_vloss < best_vloss:\n",
    "    #     best_vloss = avg_vloss\n",
    "    #     model_path = f'model_{epoch_number}_{best_vloss}'\n",
    "    #     torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
